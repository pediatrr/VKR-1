import streamlit as st
import pandas as pd
from pdpbox import pdp, get_example, info_plots
from xgboost import XGBRegressor
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
import matplotlib
st.set_page_config(page_title="PDPbox", page_icon="üö©",layout='wide')
st.header('PDPbox –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ç–æ—Ä', divider='rainbow')
col1, col2 = st.columns(2)
df = pd.read_csv('diabetes.csv')
#df['Outcome'] = df['Outcome'].astype('category')

y = df['Outcome']
X = df.drop(columns='Outcome')
#–º—É–ª—å—Ç–∏—Å–µ–ª–µ–∫—Ç
co = X.columns.tolist()
yo =  y.values.tolist()
yo = set(yo)

#targetfor=y.loc[yo]
# –î–µ–ª–∞–µ–º –º–æ–¥–µ–ª—å

#https://github.com/SauceCat/PDPbox/blob/master/tutorials/pdpbox_binary_classification.ipynb

from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split

from sklearn.ensemble import RandomForestClassifier
from sklearn.decomposition import PCA
from sklearn.pipeline import Pipeline

from interpret import show
from interpret.blackbox import PartialDependence
import streamlit
import streamlit.components.v1 as components
from interpret import show
from interpret import set_visualize_provider
from interpret.provider import InlineProvider
seed = 42

y = df['Outcome']
X = df.drop(columns='Outcome')
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=seed)

pca = PCA()
rf = RandomForestClassifier(random_state=seed)

blackbox_model = Pipeline([('pca', pca), ('rf', rf)])
blackbox_model.fit(X_train, y_train)

pdp = PartialDependence(blackbox_model, X_train)
set_visualize_provider(InlineProvider(detected_envs=['streamlit'])) #–û—á–µ–Ω—å –í–∞–∂–Ω–æ
with col1:
    streamlit.write(show(pdp.explain_global(name='–õ–æ–∫–∞–ª—å–Ω—ã–π PDP'), 0))
from streamlit_shap import st_shap
import shap


with col2:
    select_p = st.selectbox('–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏', co)
    st_shap(shap.plots.partial_dependence(select_p, blackbox_model.predict,X_test,feature_expected_value=True,ice = False, model_expected_value = True),height=400, width=1250)
with st.expander('–í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö'):
    def pdp_1_1():
        multiselect = st.multiselect('–í—ã–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤', co, default=["BMI",'Age'])
        multiselect_out = st.multiselect('–í—ã–±–µ—Ä–∏ –∫–ª–∞—Å—Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è', yo, default=1)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)  
    # —Ä–∞–∑–±–∏–≤–∫–∞
        model = XGBClassifier()
        model.fit(X_train, y_train)
        # –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º
        y_pred = model.predict(X_test)
        #2.2
        target_67 = info_plots.InteractTargetPlot(
            df=df,
            features=multiselect,
            feature_names=multiselect,
            target='Outcome',
            num_grid_points=10,
            grid_types='equal',
            percentile_ranges=None,
            grid_ranges=None,
            cust_grid_points=None,
            show_outliers=False,
            endpoints=True,
        )

        fig, axes, summary_df = target_67.plot(
            which_classes=multiselect_out,
            show_percentile=True,
            figsize=(1200, 400),
            ncols=2,
            plot_params={"gaps": {"outer_y": 0.05}},
            engine='plotly',
            template='plotly_white',
        )
        fig
if __name__ == "__main__":
        pdp_1_1()
with st.expander('–ë–û–ù–£–° Accumalated local effects'):
    from sklearn.ensemble import GradientBoostingClassifier
    from sklearn.metrics import accuracy_score
    from sklearn.model_selection import train_test_split
    from alibi.explainers import ALE, plot_ale
    import matplotlib.pyplot as plt
    import io
    from PIL import Image
    def mod(X_train, y_train, co):
        lr = GradientBoostingClassifier()
        lr.fit(X_train, y_train)

        logit_fun_lr = lr.decision_function
        proba_fun_lr = lr.predict_proba
        logit_ale_lr = ALE(logit_fun_lr,feature_names=co)
        proba_ale_lr = ALE(proba_fun_lr,feature_names=co)
        logit_exp_lr = logit_ale_lr.explain(X_train)
        proba_exp_lr = proba_ale_lr.explain(X_train)

        st.set_option('deprecation.showPyplotGlobalUse', False)

        st.title('Accumulated Local Effects plots for GB on diabets dataset')
        st.markdown (" ##### Accumulated Local Effects (ALE) - —ç—Ç–æ –º–µ—Ç–æ–¥ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —ç—Ñ—Ñ–µ–∫—Ç–æ–≤ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ —Å—Ç–∞—Ç—å–µ Apley and Zhu 'Visualizing the Effects of Predictor Variables in Black Box Supervised Learning Models'. –ê–ª–≥–æ—Ä–∏—Ç–º –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–æ–ª—É—á–∏—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã—Ö –∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –Ω–µ –∑–∞–≤–∏—Å—è—â–∏—Ö –æ—Ç –º–æ–¥–µ–ª–∏(—á–µ—Ä–Ω—ã–π —è—â–∏–∫). ")

        st.header('ALE plot for decision function')
        fig, ax = plt.subplots()
        plot_ale(logit_exp_lr, ax=ax, n_cols=2, fig_kw={'figwidth': 8, 'figheight': 5}, sharey=None)

        buf = io.BytesIO()
        plt.savefig(buf, format='png')
        buf.seek(0)

        image = Image.open(buf)
        st.image(image, caption='ALE plot for decision function', use_column_width=True)

        st.header('ALE plot for probability function')
        fig, ax = plt.subplots()
        plot_ale(proba_exp_lr, ax=ax, n_cols=2, fig_kw={'figwidth': 8, 'figheight': 5})

        buf = io.BytesIO()
        plt.savefig(buf, format='png')
        buf.seek(0)



    st.button("Reset", type="primary")
    if __name__ == "__main__":
        if 'multiselect' not in st.session_state:
            st.session_state.multiselect = co  # initialize with all features

        multiselect = st.multiselect('Multiselect', co, st.session_state.multiselect)
        if multiselect != st.session_state.multiselect:  # if the selection has changed
            st.session_state.multiselect = multiselect  # update the session state
            X = df[multiselect]
            y=y.to_numpy()
            X=X.to_numpy()
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)
            mod(X_train, y_train, multiselect)